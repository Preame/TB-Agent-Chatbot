import os
from dotenv import load_dotenv

#TODO ë¬¸ì„œ ì°¾ê¸°
# 1. ë„êµ¬ ê°€ì ¸ì˜¤ê¸° (Gemini ì „ìš©)
try:
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.vectorstores import Chroma
    from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
    from langchain_core.prompts import PromptTemplate
    from langchain_core.runnables import RunnablePassthrough
    from operator import itemgetter
except ModuleNotFoundError as e:
    import sys
    print(f"âŒ ëª¨ë“ˆ ëˆ„ë½: {e.name}")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
    print('python -m pip install --upgrade pip')
    print('python -m pip install langchain langchain-community langchain-google-genai langchain-core chromadb python-dotenv')
    input("Press Enter to exit...")
    sys.exit(1)

# í™˜ê²½ë³€ìˆ˜(.env)ì—ì„œ GOOGLE_API_KEY ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# ==========================================
# [ì„¤ì •]
# ==========================================
PDF_FILE_PATH = "my_medical_doc.pdf"  # ê°™ì€ í´ë”ì— ìˆëŠ” PDF íŒŒì¼ ì´ë¦„
CHROMA_DB_PATH = "./chroma_db"        # ì €ì¥ì†Œ í´ë”

def process_document():
    """PDF ì½ì–´ì„œ Geminiê°€ ì´í•´í•˜ëŠ” ìˆ«ìë¡œ ë³€í™˜í•´ ì €ì¥"""
    if not os.path.exists(PDF_FILE_PATH):
        print(f"âŒ ì˜¤ë¥˜: '{PDF_FILE_PATH}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None

    print("ğŸ“„ ë¬¸ì„œ ì½ëŠ” ì¤‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
    loader = PyPDFLoader(PDF_FILE_PATH)
    pages = loader.load()

    # ë¬¸ì„œë¥¼ ìë¥´ê¸°
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_documents(pages)
    
    # â­ï¸ ì¤‘ìš”: Geminiìš© ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (embedding-001)
    print("ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ ì¤‘...")
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
    
    vector_db = Chroma.from_documents(
        documents=texts,
        embedding=embeddings,
        persist_directory=CHROMA_DB_PATH
    )
    print("âœ… ë¬¸ì„œ ì €ì¥ ì™„ë£Œ!")
    return vector_db

def get_nurse_bot(vector_db):
    """Gemini ë‡Œë¥¼ ì¥ì°©í•œ ê°„í˜¸ì‚¬ ë§Œë“¤ê¸°"""
    
    # [ì¶”ë¡ í˜• í”„ë¡¬í”„íŠ¸] - ì›í•˜ì‹œë˜ ê·¸ ë¡œì§ ê·¸ëŒ€ë¡œ!
    nurse_prompt_template = """
    ë‹¹ì‹ ì€ ê²°í•µ í™˜ìë¥¼ ìƒë‹´í•˜ëŠ” 10ë…„ ì°¨ ë² í…Œë‘ ê°„í˜¸ì‚¬ì…ë‹ˆë‹¤.
    ì•„ë˜ [ì°¸ê³  ë¬¸ì„œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™˜ìì˜ [ì§ˆë¬¸]ì— ëŒ€í•´ ê¹Šì´ ìƒê°í•˜ê³  ë‹µë³€í•˜ì„¸ìš”.

    [ì°¸ê³  ë¬¸ì„œ]
    {context}

    [í™˜ìì˜ ì§ˆë¬¸]
    {question}

    [ë‹µë³€ ê°€ì´ë“œë¼ì¸]
    1. í™˜ìì˜ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ì¦ìƒì´ë‚˜ ìƒí™©ì„ íŒŒì•…í•˜ì„¸ìš”.
    2. ì°¸ê³  ë¬¸ì„œì— í•´ë‹¹ ì¦ìƒì´ ìˆëŠ”ì§€ ê¼¼ê¼¼íˆ ëŒ€ì¡°í•˜ì„¸ìš”.
    3. (ì¶”ë¡ ) ë¬¸ì„œì— ìˆë‹¤ë©´ ê·¸ê²ƒì´ ì•½ë¬¼ ë¶€ì‘ìš©ì¸ì§€, ì¼ë°˜ì ì¸ ì¦ìƒì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.
    4. ë‹µë³€ì€ ë”°ëœ»í•œ ë§íˆ¬(~í•´ìš”ì²´)ë¡œ í•˜ë˜, ì˜í•™ì  ì‚¬ì‹¤ì€ ë¬¸ì„œì— ê·¼ê±°í•´ì„œë§Œ ë§í•˜ì„¸ìš”.
    5. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë©´ "ì œê³µëœ ì •ë³´ì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ ì—†ì–´ì„œ ì •í™•í•œ ë‹µë³€ì´ ì–´ë ¤ì›Œìš”."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.
    
    ë‹µë³€:
    """
    
    PROMPT = PromptTemplate(
        template=nurse_prompt_template, 
        input_variables=["context", "question"]
    )

    # â­ï¸ ì¤‘ìš”: Gemini 1.5 Flash ëª¨ë¸ ì‚¬ìš© (ë¹ ë¥´ê³  ë¬´ë£Œ í‹°ì–´ ë„‰ë„‰í•¨)
    llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash", 
        temperature=0
    )

    # ê²€ìƒ‰ëœ ë¬¸ì„œ 3ê°œë§Œ ì°¸ê³ (k=3)í•´ì„œ ë‹µë³€ ìƒì„± (ìµœì‹  ë°©ì‹)
    retriever = vector_db.as_retriever(search_kwargs={"k": 3})
    
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)
    
    qa_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | PROMPT
        | llm
    )
    
    return qa_chain

# ==========================================
# [ì‹¤í–‰]
# ==========================================
if __name__ == "__main__":
    # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (ë¶ˆëŸ¬ì˜¬ ë•Œë„ í•„ìš”í•¨)
    gemini_embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

    # DB í™•ì¸ ë° ë¡œë“œ
    if os.path.exists(CHROMA_DB_PATH):
        print("ğŸ’¾ ê¸°ì¡´ ì§€ì‹ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
        vector_db = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=gemini_embeddings)
    else:
        vector_db = process_document()

    if vector_db:
        bot = get_nurse_bot(vector_db)
        print("\nğŸ‘©â€âš•ï¸ Gemini ê°„í˜¸ì‚¬: ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? (ì¢…ë£Œ: exit)")
        
        while True:
            user_input = input("\nğŸ‘¤ í™˜ì: ")
            if user_input.lower() == "exit":
                break
            
            try:
                response = bot.invoke(user_input)
                print(f"ğŸ‘©â€âš•ï¸ ê°„í˜¸ì‚¬: {response.content}")
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        input("Press Enter to exit...")